# 原神千星奇域·综合指南 - 网站爬取执行计划

## 1. 网站概览

- **网站地址**：https://act.mihoyo.com/ys/ugc/tutorial/detail/mh29wpicgvh0
- **内容类型**：游戏创作工具的综合指南文档
- **页面类型**：传统多页网站，非SPA应用
- **导航结构**：两级嵌套结构（主分类 + 子分类）
- **总链接数**：167个文档页面
- **布局模式**：左侧导航栏 + 右侧内容区的经典文档布局

## 2. 爬取目标与范围

### 2.1 爬取目标
- 完整获取所有167个文档页面的内容
- 保留文档的原始结构和格式
- 转换为Markdown格式便于阅读和管理
- 本地化所有链接和图片资源

### 2.2 爬取范围
- 目标域名：act.mihoyo.com
- 路径前缀：/ys/ugc/tutorial/detail/
- 文档ID格式：[a-z0-9]+（如mh29wpicgvh0）

## 3. 执行步骤

### 3.1 准备阶段
1. **环境搭建**：
   - 安装必要的依赖：`requests`, `beautifulsoup4`, `markdownify`
   - 配置日志系统，记录爬取过程和异常信息

2. **初始数据采集**：
   - 访问起始页面：https://act.mihoyo.com/ys/ugc/tutorial/detail/mh29wpicgvh0
   - 解析页面，提取所有导航链接
   - 去重处理，生成待爬取URL列表
   - 建立文档ID与中文标题的映射表

### 3.2 爬取阶段

#### 3.2.1 单页面爬取流程
```
┌─────────────────────────────────────────────────────┐
│ 1. 发送HTTP请求获取页面HTML                         │
├─────────────────────────────────────────────────────┤
│ 2. 检查响应状态码，处理异常情况                     │
├─────────────────────────────────────────────────────┤
│ 3. 使用BeautifulSoup解析HTML                        │
├─────────────────────────────────────────────────────┤
│ 4. 提取文档标题和内容（使用.doc-view选择器）        │
├─────────────────────────────────────────────────────┤
│ 5. 提取并处理页面中的所有链接                       │
├─────────────────────────────────────────────────────┤
│ 6. 提取并下载页面中的图片资源                       │
├─────────────────────────────────────────────────────┤
│ 7. 将HTML内容转换为Markdown格式                     │
├─────────────────────────────────────────────────────┤
│ 8. 更新Markdown中的链接为本地引用                   │
├─────────────────────────────────────────────────────┤
│ 9. 保存Markdown文件到本地                           │
└─────────────────────────────────────────────────────┘
```

#### 3.2.2 批量爬取策略
- **爬取顺序**：按导航结构顺序爬取，先主分类后子分类
- **并发控制**：采用异步并行爬取，最大并发数设置为5
- **爬取间隔**：每个请求间隔1-2秒，避免请求过于频繁
- **断点续爬**：记录已爬取的文档ID，支持中断后从上次位置继续

## 4. 资源定位与数据提取规则

### 4.1 资源定位

| 资源类型 | 选择器/定位规则 | 示例 |
|----------|----------------|------|
| 文档内容 | `.doc-view` CSS类 | `<div class="doc-view">...</div>` |
| 文档标题 | `document.title` | 原神千星奇域·综合指南 |
| 导航链接 | `document.querySelectorAll('a')` | `<a href="https://act.mihoyo.com/ys/ugc/tutorial/detail/mh29wpicgvh0">读前须知</a>` |
| 图片资源 | `img`标签的`src`属性 | `<img src="https://fastcdn.mihoyo.com/...">` |

### 4.2 数据提取规则

#### 4.2.1 文档内容提取
- 使用BeautifulSoup的`.select_one('.doc-view')`定位内容区域
- 保留HTML的标题层级（h1-h6）
- 保留段落、列表、表格等结构
- 移除与内容无关的导航和页脚元素

#### 4.2.2 链接处理规则
1. **链接提取**：
   - 提取所有`<a>`标签的`href`属性
   - 过滤掉非目标域名的链接（仅保留act.mihoyo.com域名）
   - 过滤掉非文档页面的链接（仅保留包含`/ys/ugc/tutorial/detail/`的链接）

2. **链接转换**：
   - 提取文档URL中的唯一ID：`/detail/(\w+)`
   - 使用映射表查找对应的中文标题
   - 将绝对URL转换为相对路径：`./中文标题.md`
   - 示例：`https://act.mihoyo.com/ys/ugc/tutorial/detail/mhz71urk21nq` → `./界面介绍.md`

#### 4.2.3 图片处理规则
1. **图片提取**：
   - 提取所有`<img>`标签的`src`属性
   - 过滤掉空值和无效URL

2. **图片下载与本地化**：
   - 下载图片到本地`images/`目录
   - 使用图片URL的哈希值作为文件名，避免命名冲突
   - 更新Markdown中的图片链接为本地路径
   - 示例：`![alt](https://fastcdn.mihoyo.com/...)` → `![alt](./images/123456.png)`

## 5. 反爬机制应对方案

### 5.1 已知反爬机制
- **请求头检查**：可能检查User-Agent和Referer字段
- **请求频率限制**：可能存在IP级别的请求频率限制
- **Cookie验证**：可能使用Cookie进行会话验证

### 5.2 应对策略

| 反爬机制 | 应对策略 | 具体实现 |
|----------|----------|----------|
| 请求头检查 | 使用真实浏览器User-Agent | 设置`User-Agent`为Chrome最新版本 |
| 请求频率限制 | 合理设置爬取间隔 | 每个请求间隔1-2秒，最大并发数5 |
| Cookie验证 | 保持会话一致性 | 复用同一个Session对象，自动处理Cookie |
| IP限制 | 考虑使用代理IP池 | 备选方案：若遇到IP限制，切换到代理IP |

## 6. 异常处理方案

### 6.1 常见异常类型

| 异常类型 | 可能原因 | 应对策略 |
|----------|----------|----------|
| HTTP 404 | 页面不存在或已删除 | 记录日志，跳过该页面 |
| HTTP 403 | 访问被拒绝 | 暂停爬取5分钟，检查User-Agent和Cookie |
| HTTP 500 | 服务器内部错误 | 重试3次，每次间隔30秒 |
| 超时错误 | 网络连接问题或服务器响应缓慢 | 重试3次，每次间隔60秒 |
| 解析错误 | HTML结构不符合预期 | 记录日志，跳过该页面或手动处理 |

### 6.2 异常处理流程

```
┌─────────────────────────────────────────────────────┐
│ 1. 捕获异常                                         │
├─────────────────────────────────────────────────────┤
│ 2. 记录异常信息到日志文件                           │
├─────────────────────────────────────────────────────┤
│ 3. 根据异常类型判断是否需要重试                     │
├─────────────────────────────────────────────────────┤
│ 4. 若需要重试：                                    │
│    a. 等待指定时间                                 │
│    b. 减少并发数                                   │
│    c. 更新请求头或Cookie                           │
│    d. 重新发起请求                                 │
├─────────────────────────────────────────────────────┤
│ 5. 若不需要重试或重试失败：                        │
│    a. 记录失败URL到失败列表                         │
│    b. 继续处理下一个URL                            │
└─────────────────────────────────────────────────────┘
```

## 7. 进度监控指标

### 7.1 实时监控指标

| 指标名称 | 单位 | 监控频率 | 说明 |
|----------|------|----------|------|
| 已爬取页面数 | 个 | 每秒 | 当前已成功爬取的页面数量 |
| 失败页面数 | 个 | 每秒 | 爬取失败的页面数量 |
| 爬取速率 | 页/分钟 | 每分钟 | 平均每分钟爬取的页面数量 |
| 剩余页面数 | 个 | 每秒 | 待爬取的页面数量 |
| 成功率 | % | 每秒 | 成功爬取的页面占总页面的百分比 |
| 平均响应时间 | 毫秒 | 每分钟 | 服务器平均响应时间 |

### 7.2 日志记录

#### 7.2.1 日志文件结构
- **文件名**：`crawl_log.txt`
- **格式**：`[时间戳] [状态] [URL] [描述]`
- **状态码**：
  - `INFO`：一般信息
  - `SUCCESS`：爬取成功
  - `ERROR`：爬取失败
  - `WARNING`：警告信息

#### 7.2.2 日志示例
```
[2026-01-03 10:00:00] INFO Starting crawl process
[2026-01-03 10:00:01] SUCCESS https://act.mihoyo.com/ys/ugc/tutorial/detail/mh29wpicgvh0 爬取成功，保存为"读前须知.md"
[2026-01-03 10:00:02] SUCCESS https://act.mihoyo.com/ys/ugc/tutorial/detail/mhs2w008wf14 爬取成功，保存为"更新日志.md"
[2026-01-03 10:00:05] ERROR https://act.mihoyo.com/ys/ugc/tutorial/detail/invalid-id 404 Not Found
[2026-01-03 10:01:00] INFO Crawl progress: 10/167 (5.99%)
```

## 8. 存储结构设计

### 8.1 目录结构
```
markdown/
├── 网站爬取执行计划.md        # 本计划文件
├── 网站导航结构报告.md        # 导航结构报告
├── 页面分析报告.md           # 页面分析报告
├── 读前须知.md              # 爬取的文档
├── 更新日志.md              # 爬取的文档
├── 界面介绍.md              # 爬取的文档
├── ...                      # 更多爬取的文档
├── images/                  # 图片资源目录
│   ├── 1234567890abcdef.png  # 本地化图片
│   └── ...                  # 更多图片
├── doc_id_map.json          # 文档ID与文件名映射表
└── crawl_log.txt            # 爬取日志
```

### 8.2 映射表结构

#### 8.2.1 文档ID映射表 (`doc_id_map.json`)
```json
{
  "mh29wpicgvh0": "读前须知",
  "mhs2w008wf14": "更新日志",
  "mhz71urk21nq": "界面介绍",
  "mhn4bsi5lb58": "整体界面",
  "mhwe1n94b1x6": "地形编辑",
  "mhnffmieeqbg": "实体摆放",
  "mhwp5h9d4h3e": "元件库",
  "mhexhcr1qjh2": "战斗预设",
  "mhn9vpia00qc": "关卡设置",
  "mhie54ik9ovg": "试玩",
  "mh9fj3rudd9q": "多人试玩",
  "mho777i0ga90": "千星沙箱",
  "mhxbd59urbfu": "资产导入导出",
  "mhq6wdimcd84": "撤销与还原",
  "mhf66q9jc4uq": "奇域资产中心",
  "mhdtk89yhd6q": "概念介绍",
  "mh2xoxrop0la": "单位",
  "mhctmgi51lpo": "玩家",
  "mh796lr44x0e": "复苏",
  "mh3ecor1x5cm": "角色",
  "mhufqo0c0tqw": "造物",
  "mhlh4n9m4i56": "物件",
  "mhciimiw86jg": "本地投射物",
  "mh3pgiraqkiu": "关卡",
  "mhjx2miruaos": "功能",
  "mh3oxo0ojgxk": "基础信息",
  "mhuqbn9yn5bu": "变换、原生碰撞、可见性和创建设置",
  "mhrutdio6904": "模型",
  "mhe1ixri46ta": "阵营",
  "mhzldmiwdgu4": "单位标签",
  "mhqmrlr6h58e": "实体布设组",
  "mhlb1vivioys": "负载优化",
  "mh6fj30p2cmo": "数据复制粘贴",
  "mhtwkur42see": "特化配置",
  "mhvyqz9xwu0q": "基础战斗属性",
  "mhw9ut96q96y": "仇恨配置",
  "mhvg40rc5w9i": "受击盒设置",
  "mha42r0cwx74": "战斗设置",
  "mh0ucw9e76f6": "能力单元",
  "mh3rgo0c16c8": "常规设置",
  "mhei6orvcbkm": "通用组件",
  "mh5jko05fzyw": "选项卡",
  "mhnmcmipncrg": "基础运动器",
  "mh8w69rzuc3i": "碰撞触发器",
  "mhso1b9wjica": "自定义变量",
  "mhaqt9rgqv4u": "投射运动器",
  "mhstl890y7xe": "角色扰动装置",
  "mhawd6rl5kpy": "全局计时器",
  "mh6rh59iil2i": "单位状态",
  "mhufb90zbnts": "定时器",
  "mh2pir0hat1s": "命中检测",
  "mhuiob9dg1dm": "额外碰撞",
  "mhuts59m9gju": "跟随运动器",
  "mh4ppo02m1o8": "特效播放",
  "mhmshmimtegs": "自定义挂接点",
  "mhn95di01j84": "碰撞触发源",
  "mhwiv89yra02": "音效播放器",
  "mh5n160t2b6w": "铭牌",
  "mhwtz297kp6a": "文本气泡",
  "mh5y5001vqd4": "背包组件",
  "mh63ox06afy8": "战利品",
  "mho6gviqhsqs": "商店组件",
  "mhfc0lr1tcke": "扫描标签",
  "mh0pppib5eyc": "小地图标识",
  "mhgkan9wgil6": "光源",
  "mhjwjrr5n73i": "节点图",
  "mhk23ora1wom": "基础概念",
  "mhb3ho0k5l2w": "节点图编辑指引",
  "mhmzm3rltetq": "资产",
  "mhe1030vx380": "特效",
  "mhw3s1ig4g0k": "预设状态",
  "mh57xz9afh7e": "技能动画",
  "mhnapxrumtzy": "界面控件",
  "mhwkfsitckrw": "交互按钮界面控件",
  "mhjja1ipq9ck": "道具展示界面控件",
  "mhnltrr3g966": "文本框界面控件",
  "mhen7r0djxkg": "弹窗界面控件",
  "mhwpzpixrad0": "进度条界面控件",
  "mhnrdor7uyra": "计时器界面控件",
  "mhesro0hyn5k": "计分板界面控件",
  "mh2teu0bmfbc": "卡牌选择器界面控件",
  "mheybl0mdcqo": "高级概念",
  "mhewyi0fjfvs": "界面控件组管理",
  "mhozt0r74ng6": "界面布局",
  "mhg1700h8bug": "界面控件组",
  "mhfua005zpeg": "主镜头",
  "mhjsw9rluwou": "外围系统",
  "mho2rt9ir6ay": "排行榜",
  "mhf45sisuup8": "竞技段位",
  "mh65jrr2yj3i": "成就",
  "mhx1du08nhwo": "关卡结算",
  "mhjdhpi4sd10": "奇域礼盒",
  "mht8l59439d6": "资源系统",
  "mhbgx0rspbqu": "道具",
  "mhkl2yin0cxo": "装备",
  "mh2cr30yeak0": "货币",
  "mhogfq9bf86q": "背包",
  "mhkfj1iilnck": "掉落物",
  "mhi9s7isvp50": "商店",
  "mho81frl33im": "技能",
  "mh6ate95agb6": "技能资源",
  "mhodlcrpht3q": "职业",
  "mhfvn30ctm9c": "预设点",
  "mhhl0gire830": "护盾",
  "mh333vim2h44": "路径",
  "mhd7nxrfa8im": "单位状态",
  "mhh5zgirw9cc": "其它概念",
  "mhzcw29qjjma": "局内存档",
  "mhk59aiqtwyk": "多语言文本",
  "mhaneb9qnvay": "文字聊天",
  "mhq9b601kh9k": "背景音乐",
  "mhdznsie9up8": "环境配置",
  "mhzhzb9rw0uy": "元件组",
  "mhsok60iqlxk": "节点介绍",
  "mhuto3r800b2": "服务器节点",
  "mhw66orrrfkm": "执行节点",
  "mhn7ko01v3yw": "事件节点",
  "mhe8yn9bysd6": "流程控制节点",
  "mhwbqlrw655q": "查询节点",
  "mhnd4l069tk0": "运算节点",
  "mhlv230i3opc": "客户端节点",
  "mholjx05ji8w": "查询节点",
  "mhfmxw9fn6n6": "运算节点",
  "mh6obvipqv1g": "执行节点",
  "mhxppurzujfq": "流程控制节点",
  "mhor3u09y7u0": "其它节点",
  "mhoyplr76zr2": "辅助功能",
  "mho2hirgodxi": "负载计算功能",
  "mhsumxr9cf3y": "附录",
  "mhrvqvioautg": "能力单元效果",
  "mhyg4i0inazs": "造物行为模式图鉴",
  "mhpsmb91keka": "造物行为模式的未入战行为",
  "mhzys1ic5eok": "造物技能说明",
  "mhou93r2pxv2": "单位状态效果池",
  "mhk7nlregm9q": "节点图高级特性",
  "mhkirfrna1fy": "泛型引脚",
  "mhtshailzs7w": "节点图变量",
  "mhty17iqeht0": "复合节点",
  "mhu951iz7wz8": "节点图日志",
  "mhrnuz9izfne": "客户端节点图日志",
  "mhip8yit341o": "复合节点图日志",
  "mhlaj0r9bldi": "信号",
  "mhubgk9yy8gy": "字典",
  "mh3fmi0t99ns": "结构体"
}
```

## 9. 单页极长内容处理方案

### 9.1 适用场景
针对内容长度超过500,000字符的单页文档，例如 `https://act.mihoyo.com/ys/ugc/tutorial/detail/mhw66orrrfkm`（执行节点页面），需要进行分段处理，以提高可读性和管理效率。

### 9.2 分段标准

| 分段依据 | 具体标准 | 示例 |
|----------|----------|------|
| 内容长度 | 单页内容超过500,000字符 | 执行节点页面（810,471字符） |
| 章节结构 | 基于h1标题进行一级分段，基于h2标题进行二级分段 | h1: "一、通用节点"，h2: "1.打印字符串" |
| 内容关联性 | 确保每段内容具有完整的主题和逻辑关系 | 同一章节的内容保持在一起 |

### 9.3 实施步骤

#### 9.3.1 检测极长内容
1. 在爬取页面后，检查内容长度
2. 若内容长度超过500,000字符，启动分段处理流程
3. 否则，按照常规流程处理

#### 9.3.2 分析章节结构
1. 使用BeautifulSoup解析HTML内容
2. 提取所有h1、h2标题及其位置
3. 构建章节层级结构树

#### 9.3.3 执行分段处理
1. **一级分段**：基于h1标题将文档分为多个主要部分
2. **二级分段**：在每个主要部分内，基于h2标题进一步细分
3. **文件命名规则**：
   - 一级分段：`原文件名_一级标题.md`（例如：`执行节点_一、通用节点.md`）
   - 二级分段：`原文件名_一级标题_二级标题.md`（例如：`执行节点_一、通用节点_1.打印字符串.md`）
4. **生成目录文件**：为每个极长文档生成一个目录文件，包含所有分段的链接

#### 9.3.4 更新链接关系
1. 在分段后的文件中，添加"上一章"、"下一章"导航链接
2. 在目录文件中，添加所有分段的索引链接
3. 更新其他文档中指向该极长文档的链接，使其指向目录文件

### 9.4 质量控制措施

| 控制项 | 具体措施 | 检查方式 |
|--------|----------|----------|
| 分段完整性 | 确保所有内容都被正确分段，无遗漏 | 比对分段前后的内容总长度 |
| 分段合理性 | 确保每段内容具有完整的主题和逻辑结构 | 人工抽查5%的分段文件 |
| 链接正确性 | 确保所有内部链接都指向正确的分段文件 | 自动检查所有链接的有效性 |
| 格式一致性 | 确保所有分段文件的格式保持一致 | 自动检查文件格式规范 |
| 可读性 | 确保分段后的文件便于阅读和管理 | 人工评估阅读体验 |

### 9.5 目录文件示例
```markdown
# 执行节点 - 目录

## 一、通用节点
- [1.打印字符串](./执行节点_一、通用节点_1.打印字符串.md)
- [2.设置局部变量](./执行节点_一、通用节点_2.设置局部变量.md)
- [3.跳出循环](./执行节点_一、通用节点_3.跳出循环.md)
- [4.有限循环](./执行节点_一、通用节点_4.有限循环.md)
- [5.转发事件](./执行节点_一、通用节点_5.转发事件.md)

## 二、列表相关
- [1.对列表插入值](./执行节点_二、列表相关_1.对列表插入值.md)
- [2.对列表修改值](./执行节点_二、列表相关_2.对列表修改值.md)
- [3.对列表移除值](./执行节点_二、列表相关_3.对列表移除值.md)

[上一章](./服务器节点.md) | [返回目录](./节点介绍.md) | [下一章](./事件节点.md)
```

## 10. 质量控制措施

### 10.1 内容完整性检查
- **标题检查**：确保每个文档都有标题
- **内容长度检查**：
  - 常规文档：确保内容长度合理（至少100字符）
  - 分段文档：确保每段内容长度合理（至少500字符）
- **结构检查**：确保文档具有合理的标题层级和段落结构

### 10.2 链接有效性验证
- **本地链接验证**：确保所有本地链接指向存在的文件
- **死链检查**：定期检查爬取的文档中是否存在死链
- **链接格式检查**：确保链接格式正确，无语法错误

### 10.3 格式一致性检查
- **标题层级**：统一使用Markdown标题格式（# - ######）
- **段落间距**：统一使用单个空行分隔段落
- **列表格式**：统一使用Markdown列表格式（- / 1.）
- **代码块**：统一使用 ``` 包裹代码块

### 10.4 定期抽样检查
- 每爬取10个文档，随机选择1个进行人工检查
- 检查内容包括：格式正确性、内容完整性、链接有效性
- 根据检查结果调整爬取策略和提取规则

## 11. 爬取完成后的验证

### 11.1 统计报告生成
- 生成爬取统计报告，包括：
  - 总页面数、成功数、失败数
  - 平均爬取速度
  - 资源使用情况
  - 常见错误类型分布

### 11.2 完整性验证
- 检查是否所有待爬取页面都已爬取
- 检查是否所有图片都已下载
- 检查映射表是否完整

### 11.3 一致性验证
- 验证本地文档的链接是否正确指向其他本地文档
- 验证图片链接是否正确指向本地图片
- 验证文档结构是否与原始页面一致

## 12. 总结

本爬取执行计划详细描述了原神千星奇域·综合指南网站的爬取方案，包括网站概览、爬取目标与范围、执行步骤、资源定位、数据提取规则、反爬机制应对、异常处理方案、进度监控指标、存储结构设计、单页极长内容处理方案、质量控制措施、爬取完成后的验证等方面。

该计划具有高度的AI智能体友好性，提供了明确的执行步骤和具体的技术实现方案，确保AI智能体能够准确理解并独立完成整个网站的爬取任务。特别是针对单页极长内容，制定了详细的分段处理方案，确保爬取内容的可读性和管理效率。

通过遵循本计划，可以高效、完整地获取网站的所有内容，并转换为便于阅读和管理的Markdown格式，同时确保爬取过程的可靠性和数据质量。